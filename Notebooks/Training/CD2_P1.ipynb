{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "bac0c89d",
   "metadata": {},
   "source": [
    "# CD2_P1"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e49f174a",
   "metadata": {},
   "source": [
    "### Import Packages"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "940fb22d",
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "from tensorflow.keras import layers, models\n",
    "from tensorflow.keras.applications import VGG16\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ecb11524",
   "metadata": {},
   "source": [
    "### Variable Paths, Execution Environments"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "a756063e",
   "metadata": {},
   "outputs": [],
   "source": [
    "modelname = 'CD2_P1'"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fe13c43b",
   "metadata": {},
   "source": [
    "I use 3 Local Machines & 2 Cloud Compute Engines (Google, Kaggle). The appropriate paths for each platform of execution are declared here."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "4c0920ae",
   "metadata": {},
   "outputs": [],
   "source": [
    "Kaggle = 0\n",
    "Colab = 0\n",
    "Local = 1\n",
    "LocalRM = 0\n",
    "LocalOldLaptop = 0\n",
    "\n",
    "# Kaggle Notebooks\n",
    "Kaggle_Dataset = '/kaggle/input/catsdogsconv/KaggleCatsDogsConv'\n",
    "Kaggle_SavedModels = '/kaggle/working/SavedModels'\n",
    "Kaggle_TrainingHistory = '/kaggle/working/TrainingHistory'\n",
    "\n",
    "# Google Drive\n",
    "GD_Dataset = '/content/drive/MyDrive/Datasets/KaggleCatsDogs'\n",
    "GD_SavedModels = '/content/drive/MyDrive/NotebookWorkspace/SavedModels'\n",
    "CD_TrainingHistory = '/content/drive/MyDrive/NotebookWorkspace/TrainingHistory'\n",
    "\n",
    "# Local Directories\n",
    "Lc_Dataset = 'C:\\\\Programming_Files\\\\JupyterVSCode\\\\Binary_Classification_Transfer_Learning\\\\CatsDogs\\\\DatasetConv'\n",
    "Lc_SavedModels = 'C:\\\\Programming_Files\\\\JupyterVSCode\\\\Binary_Classification_Transfer_Learning\\\\CatsDogs\\\\SavedModels'\n",
    "Lc_TrainingHistory = 'C:\\\\Programming_Files\\\\JupyterVSCode\\\\Binary_Classification_Transfer_Learning\\\\CatsDogs\\\\Docs_Reports\\\\RawTrainingData'\n",
    "\n",
    "Lc_RM_Dataset = \"C:\\\\Users\\\\arisi\\\\Documents\\\\VSCode\\\\CatsDogs\\\\Dataset\\\\KaggleCatsDogsConv\"\n",
    "Lc_RM_SavedModels = \"C:\\\\Users\\\\arisi\\\\Documents\\\\VSCode\\\\CatsDogs\\\\SavedModels\"\n",
    "Lc_RM_TrainingHistory = \"C:\\\\Users\\\\arisi\\\\Documents\\\\VSCode\\\\CatsDogs\\\\Docs_Reports\\\\RawTrainingData\"\n",
    "\n",
    "Lc_Old_Dataset = 'Test'\n",
    "Lc_Old_SavedModels = 'Test'\n",
    "Lc_Old_TrainingHistory = 'Test'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "6478c886",
   "metadata": {},
   "outputs": [],
   "source": [
    "if Kaggle:\n",
    "    data_dir = Kaggle_Dataset\n",
    "    SavedModelsPath = Kaggle_SavedModels\n",
    "    TrainingHistoryPath = Kaggle_TrainingHistory\n",
    "if Colab:\n",
    "    from google.colab import drive\n",
    "    drive.mount('/content/drive')\n",
    "    data_dir = GD_Dataset\n",
    "    SavedModelsPath = GD_SavedModels\n",
    "    TrainingHistoryPath = CD_TrainingHistory\n",
    "if Local:\n",
    "    data_dir = Lc_Dataset\n",
    "    SavedModelsPath = Lc_SavedModels\n",
    "    TrainingHistoryPath = Lc_TrainingHistory\n",
    "if LocalRM:\n",
    "    data_dir = Lc_RM_Dataset\n",
    "    SavedModelsPath = Lc_RM_SavedModels\n",
    "    TrainingHistoryPath = Lc_RM_TrainingHistory\n",
    "if LocalOldLaptop:\n",
    "    data_dir = Lc_Old_Dataset\n",
    "    SavedModelsPath = Lc_Old_SavedModels\n",
    "    TrainingHistoryPath = Lc_Old_TrainingHistory"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c9bffc94",
   "metadata": {},
   "source": [
    "### Load the Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "f165b96b",
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.utils import image_dataset_from_directory"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "873ab191",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 24997 files belonging to 2 classes.\n",
      "Using 19998 files for training.\n",
      "Found 24997 files belonging to 2 classes.\n",
      "Using 4999 files for validation.\n"
     ]
    }
   ],
   "source": [
    "# Load Datasets\n",
    "train_dataset = image_dataset_from_directory(\n",
    "    data_dir,\n",
    "    image_size=(224, 224),\n",
    "    batch_size=32,\n",
    "    label_mode='binary',\n",
    "    validation_split=0.2,  # 20% for validation\n",
    "    subset='training',     # Use the 'training' subset\n",
    "    seed=123\n",
    ")\n",
    "\n",
    "val_dataset = image_dataset_from_directory(\n",
    "    data_dir,\n",
    "    image_size=(224, 224),\n",
    "    batch_size=32,\n",
    "    label_mode='binary',\n",
    "    validation_split=0.2,  # 20% for validation\n",
    "    subset='validation',   # Use the 'validation' subset\n",
    "    seed=123\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d47c39f7",
   "metadata": {},
   "source": [
    "### Preprocessing & Augmentation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "b89f6432",
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.applications.vgg16 import preprocess_input"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "61d1c56f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Augmentation layer\n",
    "data_augmentation = tf.keras.Sequential([\n",
    "    layers.RandomFlip('horizontal'),\n",
    "    layers.RandomRotation(0.1),  # 10% random rotation\n",
    "    layers.RandomZoom(0.1),      # 10% zoom\n",
    "    layers.RandomTranslation(0.1, 0.1),  # Random height and width shift\n",
    "    layers.RandomBrightness(0.2)\n",
    "])\n",
    "\n",
    "# Augment the training data\n",
    "def augment_img(image, label):\n",
    "    image = data_augmentation(image)  # Apply augmentations\n",
    "    return image, label\n",
    "\n",
    "train_dataset = train_dataset.map(augment_img)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "f6a94b6b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Apply VGG-16 preprocessing\n",
    "def preprocess_img(image, label):\n",
    "    image = preprocess_input(image)  # Apply VGG16-specific preprocessing\n",
    "    return image, label\n",
    "\n",
    "train_dataset = train_dataset.map(preprocess_img)\n",
    "val_dataset = val_dataset.map(preprocess_img)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "336a78e8",
   "metadata": {},
   "source": [
    "### Load & Freeze the Pre-trained Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "a48edec7",
   "metadata": {},
   "outputs": [],
   "source": [
    "vgg_base = VGG16(weights='imagenet', include_top=False, input_shape=(224, 224, 3))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "24e56299",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Freeze the layers of VGG16 so we don't retrain them\n",
    "for layer in vgg_base.layers:\n",
    "    layer.trainable = False"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f28615f7",
   "metadata": {},
   "source": [
    "### Add the Head in the New Model & Compile"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "8b7d3b4f",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = models.Sequential([\n",
    "    vgg_base,\n",
    "    layers.GlobalAveragePooling2D(),\n",
    "    layers.Dense(128, activation='relu'),\n",
    "    layers.Dropout(0.5),\n",
    "    layers.Dense(1, activation='sigmoid') \n",
    "])\n",
    "\n",
    "model.compile(optimizer='adam', loss='binary_crossentropy', metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b95b0f56",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define the checkpoint path\n",
    "name = modelname\n",
    "checkpoint_path = f\"{SavedModelsPath}\\\\CD2\\\\{name}_{{epoch:03d}}_val{{val_loss:.4f}}.keras\"\n",
    "\n",
    "from tensorflow.keras.callbacks import ModelCheckpoint\n",
    "\n",
    "# Create the ModelCheckpoint callback\n",
    "checkpoint_callback = ModelCheckpoint(\n",
    "    filepath=checkpoint_path,\n",
    "    save_freq='epoch',              # Save every epoch\n",
    "    save_weights_only=False,\n",
    "    save_best_only=False,           # Save every time, not just best\n",
    "    monitor='val_loss',\n",
    "    verbose=1,\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1f2ef9bd",
   "metadata": {},
   "source": [
    "### Train the Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "545a046f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/3\n",
      "\u001b[1m625/625\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4s/step - accuracy: 0.9068 - loss: 0.3550\n",
      "Epoch 1: saving model to C:\\Programming_Files\\JupyterVSCode\\Binary_Classification_Transfer_Learning\\CatsDogs\\SavedModels\\CD2_P1_001_val0.0532.keras\n",
      "\u001b[1m625/625\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3093s\u001b[0m 5s/step - accuracy: 0.9068 - loss: 0.3547 - val_accuracy: 0.9820 - val_loss: 0.0532\n",
      "Epoch 2/3\n",
      "\u001b[1m625/625\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4s/step - accuracy: 0.9602 - loss: 0.1017\n",
      "Epoch 2: saving model to C:\\Programming_Files\\JupyterVSCode\\Binary_Classification_Transfer_Learning\\CatsDogs\\SavedModels\\CD2_P1_002_val0.0546.keras\n",
      "\u001b[1m625/625\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3050s\u001b[0m 5s/step - accuracy: 0.9602 - loss: 0.1017 - val_accuracy: 0.9820 - val_loss: 0.0546\n",
      "Epoch 3/3\n",
      "\u001b[1m625/625\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5s/step - accuracy: 0.9676 - loss: 0.0810\n",
      "Epoch 3: saving model to C:\\Programming_Files\\JupyterVSCode\\Binary_Classification_Transfer_Learning\\CatsDogs\\SavedModels\\CD2_P1_003_val0.0486.keras\n",
      "\u001b[1m625/625\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3623s\u001b[0m 6s/step - accuracy: 0.9676 - loss: 0.0810 - val_accuracy: 0.9836 - val_loss: 0.0486\n"
     ]
    }
   ],
   "source": [
    "history = model.fit(\n",
    "    train_dataset,\n",
    "    epochs=3,\n",
    "    validation_data=val_dataset,\n",
    "    callbacks=[checkpoint_callback]\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8d26fcd2",
   "metadata": {},
   "source": [
    "### Save History in JSON"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "ae295e38",
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "\n",
    "name = modelname\n",
    "filepath = f\"{TrainingHistoryPath}\\\\{name}.json\"\n",
    "with open(filepath, 'w') as f:\n",
    "    json.dump(history.history, f)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d36b3676",
   "metadata": {},
   "source": [
    "### Load Chosen Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "2c988f0e",
   "metadata": {},
   "outputs": [],
   "source": [
    "filepath = 'C:\\\\Programming_Files\\\\JupyterVSCode\\\\Binary_Classification_Transfer_Learning\\\\CatsDogs\\\\SavedModels\\\\CD2\\\\CD2_P1_003_val0.0486.keras'\n",
    "model = tf.keras.models.load_model(filepath)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "834969d5",
   "metadata": {},
   "source": [
    "### Continue Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "51773c5e",
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.optimizers import Adam\n",
    "optimizer = Adam(learning_rate=1e-3)\n",
    "model.compile(optimizer=optimizer, loss='binary_crossentropy', metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "315b93ac",
   "metadata": {},
   "outputs": [],
   "source": [
    "name = f'CD1_P1_continue'\n",
    "checkpoint_path = f\"{SavedModelsPath}\\\\CD2\\\\{name}_{{epoch:03d}}_val{{val_loss:.4f}}.keras\"\n",
    "\n",
    "from tensorflow.keras.callbacks import ModelCheckpoint\n",
    "\n",
    "# Create the ModelCheckpoint callback\n",
    "checkpoint_callback = ModelCheckpoint(\n",
    "    filepath=checkpoint_path,\n",
    "    save_freq='epoch',              # Save every epoch\n",
    "    save_weights_only=False,\n",
    "    save_best_only=False,           # Save every time, not just best\n",
    "    monitor='val_loss',\n",
    "    verbose=1,\n",
    ")\n",
    "\n",
    "from tensorflow.keras.callbacks import ReduceLROnPlateau\n",
    "lr_scheduler = ReduceLROnPlateau(monitor='val_loss', factor=0.5, patience=2, verbose=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "b7967fdc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/4\n",
      "\u001b[1m625/625\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4s/step - accuracy: 0.9672 - loss: 0.0900\n",
      "Epoch 1: saving model to C:\\Programming_Files\\JupyterVSCode\\Binary_Classification_Transfer_Learning\\CatsDogs\\SavedModels\\CD2\\CD1_P1_continue_001_val0.0460.keras\n",
      "\u001b[1m625/625\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2977s\u001b[0m 5s/step - accuracy: 0.9672 - loss: 0.0900 - val_accuracy: 0.9848 - val_loss: 0.0460 - learning_rate: 0.0010\n",
      "Epoch 2/4\n",
      "\u001b[1m625/625\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4s/step - accuracy: 0.9698 - loss: 0.0778\n",
      "Epoch 2: saving model to C:\\Programming_Files\\JupyterVSCode\\Binary_Classification_Transfer_Learning\\CatsDogs\\SavedModels\\CD2\\CD1_P1_continue_002_val0.0499.keras\n",
      "\u001b[1m625/625\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2972s\u001b[0m 5s/step - accuracy: 0.9698 - loss: 0.0778 - val_accuracy: 0.9844 - val_loss: 0.0499 - learning_rate: 0.0010\n",
      "Epoch 3/4\n",
      "\u001b[1m625/625\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4s/step - accuracy: 0.9714 - loss: 0.0706\n",
      "Epoch 3: saving model to C:\\Programming_Files\\JupyterVSCode\\Binary_Classification_Transfer_Learning\\CatsDogs\\SavedModels\\CD2\\CD1_P1_continue_003_val0.0456.keras\n",
      "\u001b[1m625/625\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2979s\u001b[0m 5s/step - accuracy: 0.9714 - loss: 0.0706 - val_accuracy: 0.9846 - val_loss: 0.0456 - learning_rate: 0.0010\n",
      "Epoch 4/4\n",
      "\u001b[1m625/625\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4s/step - accuracy: 0.9722 - loss: 0.0703\n",
      "Epoch 4: saving model to C:\\Programming_Files\\JupyterVSCode\\Binary_Classification_Transfer_Learning\\CatsDogs\\SavedModels\\CD2\\CD1_P1_continue_004_val0.0456.keras\n",
      "\u001b[1m625/625\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2975s\u001b[0m 5s/step - accuracy: 0.9722 - loss: 0.0703 - val_accuracy: 0.9850 - val_loss: 0.0456 - learning_rate: 0.0010\n"
     ]
    }
   ],
   "source": [
    "history2 = model.fit(\n",
    "    train_dataset,\n",
    "    epochs=4,\n",
    "    validation_data=val_dataset,\n",
    "    callbacks=[checkpoint_callback, lr_scheduler]\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "2a2d6a8c",
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "\n",
    "name = 'CD1_P1_continue'\n",
    "filepath = f\"{TrainingHistoryPath}\\\\{name}.json\"\n",
    "with open(filepath, 'w') as f:\n",
    "    json.dump(history2.history, f)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "583eb6eb",
   "metadata": {},
   "source": [
    "### Load Chosen Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "48abc053",
   "metadata": {},
   "outputs": [],
   "source": [
    "filepath = 'C:\\\\Programming_Files\\\\JupyterVSCode\\\\Binary_Classification_Transfer_Learning\\\\CatsDogs\\\\SavedModels\\\\CD2\\\\CD2_P1_003_val0.0486.keras'\n",
    "model = tf.keras.models.load_model(filepath)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b057fe05",
   "metadata": {},
   "source": [
    "### Continue Training (B)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "e2964d2f",
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.optimizers import Adam\n",
    "optimizer = Adam(learning_rate=1e-4)\n",
    "model.compile(optimizer=optimizer, loss='binary_crossentropy', metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "bab3db7d",
   "metadata": {},
   "outputs": [],
   "source": [
    "name = f'CD1_P1_continueB'\n",
    "checkpoint_path = f\"{SavedModelsPath}\\\\CD2\\\\{name}_{{epoch:03d}}_val{{val_loss:.4f}}.keras\"\n",
    "\n",
    "from tensorflow.keras.callbacks import ModelCheckpoint\n",
    "\n",
    "# Create the ModelCheckpoint callback\n",
    "checkpoint_callback = ModelCheckpoint(\n",
    "    filepath=checkpoint_path,\n",
    "    save_freq='epoch',              # Save every epoch\n",
    "    save_weights_only=False,\n",
    "    save_best_only=False,           # Save every time, not just best\n",
    "    monitor='val_loss',\n",
    "    verbose=1,\n",
    ")\n",
    "\n",
    "from tensorflow.keras.callbacks import ReduceLROnPlateau\n",
    "lr_scheduler = ReduceLROnPlateau(monitor='val_loss', factor=0.5, patience=2, verbose=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "0c9ac6d2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/4\n",
      "\u001b[1m625/625\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4s/step - accuracy: 0.9721 - loss: 0.0738\n",
      "Epoch 1: saving model to C:\\Programming_Files\\JupyterVSCode\\Binary_Classification_Transfer_Learning\\CatsDogs\\SavedModels\\CD2\\CD1_P1_continueB_001_val0.0498.keras\n",
      "\u001b[1m625/625\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2969s\u001b[0m 5s/step - accuracy: 0.9721 - loss: 0.0738 - val_accuracy: 0.9842 - val_loss: 0.0498 - learning_rate: 1.0000e-04\n",
      "Epoch 2/4\n",
      "\u001b[1m625/625\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4s/step - accuracy: 0.9747 - loss: 0.0676\n",
      "Epoch 2: saving model to C:\\Programming_Files\\JupyterVSCode\\Binary_Classification_Transfer_Learning\\CatsDogs\\SavedModels\\CD2\\CD1_P1_continueB_002_val0.0493.keras\n",
      "\u001b[1m625/625\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2977s\u001b[0m 5s/step - accuracy: 0.9747 - loss: 0.0676 - val_accuracy: 0.9854 - val_loss: 0.0493 - learning_rate: 1.0000e-04\n",
      "Epoch 3/4\n",
      "\u001b[1m625/625\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4s/step - accuracy: 0.9726 - loss: 0.0708\n",
      "Epoch 3: saving model to C:\\Programming_Files\\JupyterVSCode\\Binary_Classification_Transfer_Learning\\CatsDogs\\SavedModels\\CD2\\CD1_P1_continueB_003_val0.0470.keras\n",
      "\u001b[1m625/625\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2976s\u001b[0m 5s/step - accuracy: 0.9726 - loss: 0.0708 - val_accuracy: 0.9850 - val_loss: 0.0470 - learning_rate: 1.0000e-04\n",
      "Epoch 4/4\n",
      "\u001b[1m625/625\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4s/step - accuracy: 0.9724 - loss: 0.0688\n",
      "Epoch 4: saving model to C:\\Programming_Files\\JupyterVSCode\\Binary_Classification_Transfer_Learning\\CatsDogs\\SavedModels\\CD2\\CD1_P1_continueB_004_val0.0481.keras\n",
      "\u001b[1m625/625\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2992s\u001b[0m 5s/step - accuracy: 0.9724 - loss: 0.0688 - val_accuracy: 0.9848 - val_loss: 0.0481 - learning_rate: 1.0000e-04\n"
     ]
    }
   ],
   "source": [
    "history2b = model.fit(\n",
    "    train_dataset,\n",
    "    epochs=4,\n",
    "    validation_data=val_dataset,\n",
    "    callbacks=[checkpoint_callback, lr_scheduler]\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "8e6f2d0f",
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "\n",
    "name = 'CD1_P1_continueB'\n",
    "filepath = f\"{TrainingHistoryPath}\\\\{name}.json\"\n",
    "with open(filepath, 'w') as f:\n",
    "    json.dump(history2.history, f)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "EnvPy3_12",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
