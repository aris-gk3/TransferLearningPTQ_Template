{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "bac0c89d",
   "metadata": {},
   "source": [
    "# CD1_P1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ec74335d",
   "metadata": {},
   "outputs": [],
   "source": [
    "modelname = 'CD1_P1'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fda8c395",
   "metadata": {},
   "outputs": [],
   "source": [
    "from dotenv import load_dotenv\n",
    "import os\n",
    "\n",
    "load_dotenv()  # loads variables from .env into os.environ\n",
    "\n",
    "platform = os.getenv(\"PLATFORM\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c32b7033",
   "metadata": {},
   "outputs": [],
   "source": [
    "# For Kaggle Notebooks ignore above cell & run this\n",
    "# platform = 'Kaggle'"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9b7bb6d7",
   "metadata": {},
   "source": [
    "### Variable Paths, Execution Environments"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1d09ddf9",
   "metadata": {},
   "outputs": [],
   "source": [
    "from utilpackage.Path import PathDefinition\n",
    "\n",
    "# I use 3 Local Machines & 2 Cloud Compute Engines (Google, Kaggle). The appropriate paths for each platform of execution are declared here.\n",
    "# Platform Names: 'Kaggle', 'Colab', 'Local', 'LocalRM', 'LocalOldLaptop'\n",
    "pathBase, pathDataset, pathRawData, pathJoinedData, pathSavedModels = PathDefinition(platform)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "573c2830",
   "metadata": {},
   "source": [
    "### CD 1 Model, P1 Parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "940fb22d",
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "from tensorflow.keras import layers, models\n",
    "from tensorflow.keras.applications import VGG16\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c9bffc94",
   "metadata": {},
   "source": [
    "### Load the Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "f165b96b",
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.utils import image_dataset_from_directory"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "873ab191",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 24997 files belonging to 2 classes.\n",
      "Using 19998 files for training.\n",
      "Found 24997 files belonging to 2 classes.\n",
      "Using 4999 files for validation.\n"
     ]
    }
   ],
   "source": [
    "# Define paths to training and validation datasets\n",
    "data_dir = pathDataset\n",
    "\n",
    "# Load Datasets\n",
    "train_dataset = image_dataset_from_directory(\n",
    "    data_dir,\n",
    "    image_size=(224, 224),\n",
    "    batch_size=32,\n",
    "    label_mode='binary',\n",
    "    validation_split=0.2,  # 20% for validation\n",
    "    subset='training',     # Use the 'training' subset\n",
    "    seed=123\n",
    ")\n",
    "\n",
    "val_dataset = image_dataset_from_directory(\n",
    "    data_dir,\n",
    "    image_size=(224, 224),\n",
    "    batch_size=32,\n",
    "    label_mode='binary',\n",
    "    validation_split=0.2,  # 20% for validation\n",
    "    subset='validation',   # Use the 'validation' subset\n",
    "    seed=123\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d47c39f7",
   "metadata": {},
   "source": [
    "### Preprocessing & Augmentation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b89f6432",
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.applications.vgg16 import preprocess_input"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "61d1c56f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Augmentation layer\n",
    "data_augmentation = tf.keras.Sequential([\n",
    "    layers.RandomFlip('horizontal'),\n",
    "    layers.RandomRotation(0.1),  # 10% random rotation\n",
    "    layers.RandomZoom(0.1),      # 10% zoom\n",
    "    layers.RandomTranslation(0.1, 0.1),  # Random height and width shift\n",
    "    layers.RandomBrightness(0.2)\n",
    "])\n",
    "\n",
    "# Augment the training data\n",
    "def augment_img(image, label):\n",
    "    image = data_augmentation(image)  # Apply augmentations\n",
    "    return image, label\n",
    "\n",
    "train_dataset = train_dataset.map(augment_img)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "f6a94b6b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Apply VGG-16 preprocessing\n",
    "def preprocess_img(image, label):\n",
    "    image = preprocess_input(image)  # Apply VGG16-specific preprocessing\n",
    "    return image, label\n",
    "\n",
    "train_dataset = train_dataset.map(preprocess_img)\n",
    "val_dataset = val_dataset.map(preprocess_img)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "336a78e8",
   "metadata": {},
   "source": [
    "### Load & Freeze the Pre-trained Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "a48edec7",
   "metadata": {},
   "outputs": [],
   "source": [
    "vgg_base = VGG16(weights='imagenet', include_top=False, input_shape=(224, 224, 3))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "24e56299",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Freeze the layers of VGG16 so we don't retrain them\n",
    "for layer in vgg_base.layers:\n",
    "    layer.trainable = False"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f28615f7",
   "metadata": {},
   "source": [
    "### Add the Head in the New Model & Compile"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "8b7d3b4f",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = models.Sequential([\n",
    "    vgg_base,\n",
    "    layers.Flatten(),\n",
    "    layers.Dense(512, activation='relu'),\n",
    "    layers.Dropout(0.5),\n",
    "    layers.Dense(1, activation='sigmoid')  # For binary classification\n",
    "])\n",
    "\n",
    "model.compile(optimizer='adam', loss='binary_crossentropy', metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "b95b0f56",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define the checkpoint path\n",
    "model_name = model.name\n",
    "checkpoint_path = f\"{model_name}_head_epoch{{epoch:03d}}_val{{val_loss:.4f}}.keras\"\n",
    "\n",
    "from tensorflow.keras.callbacks import ModelCheckpoint\n",
    "\n",
    "# Create the ModelCheckpoint callback\n",
    "checkpoint_callback = ModelCheckpoint(\n",
    "    filepath=checkpoint_path,\n",
    "    save_freq='epoch',              # Save every epoch\n",
    "    save_weights_only=False,\n",
    "    save_best_only=False,           # Save every time, not just best\n",
    "    monitor='val_loss',\n",
    "    verbose=1,\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1f2ef9bd",
   "metadata": {},
   "source": [
    "### Train the Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "545a046f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/2\n",
      "\u001b[1m625/625\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5s/step - accuracy: 0.9234 - loss: 2.9528\n",
      "Epoch 1: saving model to sequential_1_head_epoch001_val0.0849.keras\n",
      "\u001b[1m625/625\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3502s\u001b[0m 6s/step - accuracy: 0.9234 - loss: 2.9499 - val_accuracy: 0.9816 - val_loss: 0.0849\n",
      "Epoch 2/2\n",
      "\u001b[1m625/625\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4s/step - accuracy: 0.9583 - loss: 0.1269\n",
      "Epoch 2: saving model to sequential_1_head_epoch002_val0.0556.keras\n",
      "\u001b[1m625/625\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3356s\u001b[0m 5s/step - accuracy: 0.9583 - loss: 0.1269 - val_accuracy: 0.9842 - val_loss: 0.0556\n"
     ]
    }
   ],
   "source": [
    "history = model.fit(\n",
    "    train_dataset,\n",
    "    epochs=2,\n",
    "    validation_data=val_dataset,\n",
    "    callbacks=[checkpoint_callback]\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8d26fcd2",
   "metadata": {},
   "source": [
    "### Save History in JSON"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ae295e38",
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "import numpy as np\n",
    "\n",
    "model_name = model.name\n",
    "# Assuming 'history' is the keras.callbacks.History object\n",
    "filepath = f\"{model_name}_2epochs_training_history.json\"\n",
    "with open(filepath, 'w') as f:\n",
    "    json.dump(history.history, f)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "834969d5",
   "metadata": {},
   "source": [
    "### Continue Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "315b93ac",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define the checkpoint path\n",
    "model_name = 'CD_1P1_2_6epochs'\n",
    "checkpoint_path = f\"{model_name}_head_epoch{{epoch:03d}}_val{{val_loss:.4f}}.keras\"\n",
    "\n",
    "from tensorflow.keras.callbacks import ModelCheckpoint\n",
    "\n",
    "# Create the ModelCheckpoint callback\n",
    "checkpoint_callback = ModelCheckpoint(\n",
    "    filepath=checkpoint_path,\n",
    "    save_freq='epoch',              # Save every epoch\n",
    "    save_weights_only=False,\n",
    "    save_best_only=False,           # Save every time, not just best\n",
    "    monitor='val_loss',\n",
    "    verbose=1,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "b7967fdc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/4\n",
      "\u001b[1m625/625\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4s/step - accuracy: 0.9591 - loss: 0.1118\n",
      "Epoch 1: saving model to CD_1P1_2_6epochs_head_epoch001_val0.0660.keras\n",
      "\u001b[1m625/625\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3035s\u001b[0m 5s/step - accuracy: 0.9591 - loss: 0.1118 - val_accuracy: 0.9830 - val_loss: 0.0660\n",
      "Epoch 2/4\n",
      "\u001b[1m625/625\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4s/step - accuracy: 0.9633 - loss: 0.0991\n",
      "Epoch 2: saving model to CD_1P1_2_6epochs_head_epoch002_val0.0605.keras\n",
      "\u001b[1m625/625\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2990s\u001b[0m 5s/step - accuracy: 0.9633 - loss: 0.0991 - val_accuracy: 0.9846 - val_loss: 0.0605\n",
      "Epoch 3/4\n",
      "\u001b[1m625/625\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6s/step - accuracy: 0.9630 - loss: 0.1029\n",
      "Epoch 3: saving model to CD_1P1_2_6epochs_head_epoch003_val0.0664.keras\n",
      "\u001b[1m625/625\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4405s\u001b[0m 7s/step - accuracy: 0.9630 - loss: 0.1029 - val_accuracy: 0.9826 - val_loss: 0.0664\n",
      "Epoch 4/4\n",
      "\u001b[1m625/625\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4s/step - accuracy: 0.9634 - loss: 0.1100\n",
      "Epoch 4: saving model to CD_1P1_2_6epochs_head_epoch004_val0.0686.keras\n",
      "\u001b[1m625/625\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3001s\u001b[0m 5s/step - accuracy: 0.9634 - loss: 0.1100 - val_accuracy: 0.9836 - val_loss: 0.0686\n"
     ]
    }
   ],
   "source": [
    "history2 = model.fit(\n",
    "    train_dataset,\n",
    "    epochs=4,\n",
    "    validation_data=val_dataset,\n",
    "    callbacks=[checkpoint_callback]\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2a2d6a8c",
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "import numpy as np\n",
    "\n",
    "model_name = model.name\n",
    "# Assuming 'history' is the keras.callbacks.History object\n",
    "filepath = f\"{model_name}_2epochs_training_history.json\"\n",
    "with open(filepath, 'w') as f:\n",
    "    json.dump(history.history, f)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "EnvPy3_12",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
