{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "bac0c89d",
   "metadata": {},
   "source": [
    "# CD2_P1_FT"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ecb11524",
   "metadata": {},
   "source": [
    "### Variable Paths, Execution Environments"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "a756063e",
   "metadata": {},
   "outputs": [],
   "source": [
    "modelname = 'CD2_P1_FT'"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fe13c43b",
   "metadata": {},
   "source": [
    "I use 3 Local Machines & 2 Cloud Compute Engines (Google, Kaggle). The appropriate paths for each platform of execution are declared here."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "4c0920ae",
   "metadata": {},
   "outputs": [],
   "source": [
    "Kaggle = 0\n",
    "Colab = 0\n",
    "Local = 1\n",
    "LocalRM = 0\n",
    "LocalOldLaptop = 0\n",
    "\n",
    "# Kaggle Notebooks\n",
    "Kaggle_Dataset = '/kaggle/input/catsdogsconv/KaggleCatsDogsConv'\n",
    "Kaggle_SavedModels = '/kaggle/working/SavedModels'\n",
    "Kaggle_TrainingHistory = '/kaggle/working/TrainingHistory'\n",
    "\n",
    "# Google Drive\n",
    "GD_Dataset = '/content/drive/MyDrive/Datasets/KaggleCatsDogs'\n",
    "GD_SavedModels = '/content/drive/MyDrive/NotebookWorkspace/SavedModels'\n",
    "CD_TrainingHistory = '/content/drive/MyDrive/NotebookWorkspace/TrainingHistory'\n",
    "\n",
    "# Local Directories\n",
    "Lc_Dataset = 'C:\\\\Programming_Files\\\\JupyterVSCode\\\\Binary_Classification_Transfer_Learning\\\\CatsDogs\\\\DatasetConv'\n",
    "Lc_SavedModels = 'C:\\\\Programming_Files\\\\JupyterVSCode\\\\Binary_Classification_Transfer_Learning\\\\CatsDogs\\\\SavedModels'\n",
    "Lc_TrainingHistory = 'C:\\\\Programming_Files\\\\JupyterVSCode\\\\Binary_Classification_Transfer_Learning\\\\CatsDogs\\\\Docs_Reports\\\\RawTrainingData'\n",
    "\n",
    "Lc_RM_Dataset = \"C:\\\\Users\\\\arisi\\\\Documents\\\\VSCode\\\\CatsDogs\\\\Dataset\\\\KaggleCatsDogsConv\"\n",
    "Lc_RM_SavedModels = \"C:\\\\Users\\\\arisi\\\\Documents\\\\VSCode\\\\CatsDogs\\\\SavedModels\"\n",
    "Lc_RM_TrainingHistory = \"C:\\\\Users\\\\arisi\\\\Documents\\\\VSCode\\\\CatsDogs\\\\Docs_Reports\\\\RawTrainingData\"\n",
    "\n",
    "Lc_Old_Dataset = 'Test'\n",
    "Lc_Old_SavedModels = 'Test'\n",
    "Lc_Old_TrainingHistory = 'Test'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "6478c886",
   "metadata": {},
   "outputs": [],
   "source": [
    "if Kaggle:\n",
    "    data_dir = Kaggle_Dataset\n",
    "    SavedModelsPath = Kaggle_SavedModels\n",
    "    TrainingHistoryPath = Kaggle_TrainingHistory\n",
    "if Colab:\n",
    "    from google.colab import drive\n",
    "    drive.mount('/content/drive')\n",
    "    data_dir = GD_Dataset\n",
    "    SavedModelsPath = GD_SavedModels\n",
    "    TrainingHistoryPath = CD_TrainingHistory\n",
    "if Local:\n",
    "    data_dir = Lc_Dataset\n",
    "    SavedModelsPath = Lc_SavedModels\n",
    "    TrainingHistoryPath = Lc_TrainingHistory\n",
    "if LocalRM:\n",
    "    data_dir = Lc_RM_Dataset\n",
    "    SavedModelsPath = Lc_RM_SavedModels\n",
    "    TrainingHistoryPath = Lc_RM_TrainingHistory\n",
    "if LocalOldLaptop:\n",
    "    data_dir = Lc_Old_Dataset\n",
    "    SavedModelsPath = Lc_Old_SavedModels\n",
    "    TrainingHistoryPath = Lc_Old_TrainingHistory"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "573c2830",
   "metadata": {},
   "source": [
    "### Import Packages"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "940fb22d",
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "from tensorflow.keras import layers, models\n",
    "from tensorflow.keras.applications import VGG16"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c9bffc94",
   "metadata": {},
   "source": [
    "### Load the Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "f165b96b",
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.utils import image_dataset_from_directory"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "873ab191",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 24997 files belonging to 2 classes.\n",
      "Using 19998 files for training.\n",
      "Found 24997 files belonging to 2 classes.\n",
      "Using 4999 files for validation.\n"
     ]
    }
   ],
   "source": [
    "# Load Datasets\n",
    "train_dataset = image_dataset_from_directory(\n",
    "    data_dir,\n",
    "    image_size=(224, 224),\n",
    "    batch_size=32,\n",
    "    label_mode='binary',\n",
    "    validation_split=0.2,  # 20% for validation\n",
    "    subset='training',     # Use the 'training' subset\n",
    "    seed=123\n",
    ")\n",
    "\n",
    "val_dataset = image_dataset_from_directory(\n",
    "    data_dir,\n",
    "    image_size=(224, 224),\n",
    "    batch_size=32,\n",
    "    label_mode='binary',\n",
    "    validation_split=0.2,  # 20% for validation\n",
    "    subset='validation',   # Use the 'validation' subset\n",
    "    seed=123\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d47c39f7",
   "metadata": {},
   "source": [
    "### Preprocessing & Augmentation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "b89f6432",
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.applications.vgg16 import preprocess_input"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "61d1c56f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Augmentation layer\n",
    "data_augmentation = tf.keras.Sequential([\n",
    "    layers.RandomFlip('horizontal'),\n",
    "    layers.RandomRotation(0.1),  # 10% random rotation\n",
    "    layers.RandomZoom(0.1),      # 10% zoom\n",
    "    layers.RandomTranslation(0.1, 0.1),  # Random height and width shift\n",
    "    layers.RandomBrightness(0.2)\n",
    "])\n",
    "\n",
    "# Augment the training data\n",
    "def augment_img(image, label):\n",
    "    image = data_augmentation(image)  # Apply augmentations\n",
    "    return image, label\n",
    "\n",
    "train_dataset = train_dataset.map(augment_img)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "f6a94b6b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Apply VGG-16 preprocessing\n",
    "def preprocess_img(image, label):\n",
    "    image = preprocess_input(image)  # Apply VGG16-specific preprocessing\n",
    "    return image, label\n",
    "\n",
    "train_dataset = train_dataset.map(preprocess_img)\n",
    "val_dataset = val_dataset.map(preprocess_img)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d36b3676",
   "metadata": {},
   "source": [
    "### Load Model with Trained Head"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "2c988f0e",
   "metadata": {},
   "outputs": [],
   "source": [
    "filepath = f'{SavedModelsPath}\\\\CD2\\\\CD2_P1_003_val0.0486.keras'\n",
    "model = tf.keras.models.load_model(filepath)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fddc8d77",
   "metadata": {},
   "source": [
    "### Unfreeze Last VGG Block & Verify"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "8c60729a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Layer 0: vgg16, Trainable: True\n",
      "Layer 1: global_average_pooling2d, Trainable: True\n",
      "Layer 2: dense, Trainable: True\n",
      "Layer 3: dropout, Trainable: True\n",
      "Layer 4: dense_1, Trainable: True\n"
     ]
    }
   ],
   "source": [
    "# Unfreeze the last few layers (e.g., last 4 layers)\n",
    "for layer in model.layers[-4:]:\n",
    "    layer.trainable = True\n",
    "\n",
    "# Optionally, print trainable status\n",
    "for i, layer in enumerate(model.layers):\n",
    "    print(f\"Layer {i}: {layer.name}, Trainable: {layer.trainable}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "0ac8fa7b",
   "metadata": {},
   "outputs": [],
   "source": [
    "for layer in model.layers[0].layers:\n",
    "    if layer.name in ['block5_conv1', 'block5_conv2', 'block5_conv3']:\n",
    "        layer.trainable = True\n",
    "    else:\n",
    "        layer.trainable = False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "45400541",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "- vgg16 (Functional), Trainable: True\n",
      "  - input_layer_1 (InputLayer), Trainable: False\n",
      "  - block1_conv1 (Conv2D), Trainable: False\n",
      "  - block1_conv2 (Conv2D), Trainable: False\n",
      "  - block1_pool (MaxPooling2D), Trainable: False\n",
      "  - block2_conv1 (Conv2D), Trainable: False\n",
      "  - block2_conv2 (Conv2D), Trainable: False\n",
      "  - block2_pool (MaxPooling2D), Trainable: False\n",
      "  - block3_conv1 (Conv2D), Trainable: False\n",
      "  - block3_conv2 (Conv2D), Trainable: False\n",
      "  - block3_conv3 (Conv2D), Trainable: False\n",
      "  - block3_pool (MaxPooling2D), Trainable: False\n",
      "  - block4_conv1 (Conv2D), Trainable: False\n",
      "  - block4_conv2 (Conv2D), Trainable: False\n",
      "  - block4_conv3 (Conv2D), Trainable: False\n",
      "  - block4_pool (MaxPooling2D), Trainable: False\n",
      "  - block5_conv1 (Conv2D), Trainable: True\n",
      "  - block5_conv2 (Conv2D), Trainable: True\n",
      "  - block5_conv3 (Conv2D), Trainable: True\n",
      "  - block5_pool (MaxPooling2D), Trainable: False\n",
      "- global_average_pooling2d (GlobalAveragePooling2D), Trainable: True\n",
      "- dense (Dense), Trainable: True\n",
      "- dropout (Dropout), Trainable: True\n",
      "- dense_1 (Dense), Trainable: True\n",
      "{'name': 'adam', 'learning_rate': 0.0010000000474974513, 'weight_decay': None, 'clipnorm': None, 'global_clipnorm': None, 'clipvalue': None, 'use_ema': False, 'ema_momentum': 0.99, 'ema_overwrite_frequency': None, 'loss_scale_factor': None, 'gradient_accumulation_steps': None, 'beta_1': 0.9, 'beta_2': 0.999, 'epsilon': 1e-07, 'amsgrad': False}\n"
     ]
    }
   ],
   "source": [
    "def print_model_layers(model, indent=0):\n",
    "    for layer in model.layers:\n",
    "        print(\" \" * indent + f\"- {layer.name} ({layer.__class__.__name__}), Trainable: {layer.trainable}\")\n",
    "        # If this layer has sublayers (like Functional or Sequential models)\n",
    "        if hasattr(layer, 'layers'):\n",
    "            print_model_layers(layer, indent + 2)\n",
    "\n",
    "print_model_layers(model)\n",
    "\n",
    "print(model.optimizer.get_config())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "834969d5",
   "metadata": {},
   "source": [
    "### Compile"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "315b93ac",
   "metadata": {},
   "outputs": [],
   "source": [
    "name = f'{modelname}'\n",
    "checkpoint_path = f\"{SavedModelsPath}\\\\CD2\\\\{name}_{{epoch:03d}}_val{{val_loss:.4f}}.keras\"\n",
    "\n",
    "from tensorflow.keras.callbacks import ModelCheckpoint\n",
    "\n",
    "# Create the ModelCheckpoint callback\n",
    "checkpoint_callback = ModelCheckpoint(\n",
    "    filepath=checkpoint_path,\n",
    "    save_freq='epoch',              # Save every epoch\n",
    "    save_weights_only=False,\n",
    "    save_best_only=False,           # Save every time, not just best\n",
    "    monitor='val_loss',\n",
    "    verbose=1,\n",
    ")\n",
    "\n",
    "from tensorflow.keras.callbacks import ReduceLROnPlateau\n",
    "lr_scheduler = ReduceLROnPlateau(monitor='val_loss', factor=0.5, patience=2, verbose=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "8962dd0f",
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.optimizers import Adam\n",
    "optimizer = Adam(learning_rate=5*1e-5)\n",
    "\n",
    "model.compile(optimizer=optimizer, loss='binary_crossentropy', metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b3289a9f",
   "metadata": {},
   "source": [
    "### Train & Save Results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "b7967fdc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/4\n",
      "\u001b[1m625/625\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5s/step - accuracy: 0.9613 - loss: 0.1092\n",
      "Epoch 1: saving model to C:\\Programming_Files\\JupyterVSCode\\Binary_Classification_Transfer_Learning\\CatsDogs\\SavedModels\\CD2\\CD2_P1_FT_001_val0.0394.keras\n",
      "\u001b[1m625/625\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3698s\u001b[0m 6s/step - accuracy: 0.9613 - loss: 0.1092 - val_accuracy: 0.9882 - val_loss: 0.0394 - learning_rate: 5.0000e-05\n",
      "Epoch 2/4\n",
      "\u001b[1m625/625\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4s/step - accuracy: 0.9793 - loss: 0.0556\n",
      "Epoch 2: saving model to C:\\Programming_Files\\JupyterVSCode\\Binary_Classification_Transfer_Learning\\CatsDogs\\SavedModels\\CD2\\CD2_P1_FT_002_val0.0683.keras\n",
      "\u001b[1m625/625\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3410s\u001b[0m 5s/step - accuracy: 0.9793 - loss: 0.0556 - val_accuracy: 0.9790 - val_loss: 0.0683 - learning_rate: 5.0000e-05\n",
      "Epoch 3/4\n",
      "\u001b[1m625/625\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5s/step - accuracy: 0.9797 - loss: 0.0493\n",
      "Epoch 3: saving model to C:\\Programming_Files\\JupyterVSCode\\Binary_Classification_Transfer_Learning\\CatsDogs\\SavedModels\\CD2\\CD2_P1_FT_003_val0.0455.keras\n",
      "\n",
      "Epoch 3: ReduceLROnPlateau reducing learning rate to 2.499999936844688e-05.\n",
      "\u001b[1m625/625\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3439s\u001b[0m 6s/step - accuracy: 0.9797 - loss: 0.0493 - val_accuracy: 0.9858 - val_loss: 0.0455 - learning_rate: 5.0000e-05\n",
      "Epoch 4/4\n",
      "\u001b[1m625/625\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 17s/step - accuracy: 0.9899 - loss: 0.0319 \n",
      "Epoch 4: saving model to C:\\Programming_Files\\JupyterVSCode\\Binary_Classification_Transfer_Learning\\CatsDogs\\SavedModels\\CD2\\CD2_P1_FT_004_val0.0524.keras\n",
      "\u001b[1m625/625\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11029s\u001b[0m 18s/step - accuracy: 0.9899 - loss: 0.0319 - val_accuracy: 0.9870 - val_loss: 0.0524 - learning_rate: 2.5000e-05\n"
     ]
    }
   ],
   "source": [
    "history = model.fit(\n",
    "    train_dataset,\n",
    "    epochs=4,\n",
    "    validation_data=val_dataset,\n",
    "    callbacks=[checkpoint_callback, lr_scheduler]\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "2a2d6a8c",
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "\n",
    "name = f'{modelname}'\n",
    "filepath = f\"{TrainingHistoryPath}\\\\{name}.json\"\n",
    "with open(filepath, 'w') as f:\n",
    "    json.dump(history.history, f)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "583eb6eb",
   "metadata": {},
   "source": [
    "### Continue Training (2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "48abc053",
   "metadata": {},
   "outputs": [],
   "source": [
    "history2 = model.fit(\n",
    "    train_dataset,\n",
    "    epochs=5,\n",
    "    validation_data=val_dataset,\n",
    "    callbacks=[checkpoint_callback, lr_scheduler]\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e2964d2f",
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "\n",
    "name = f'{modelname}_continue'\n",
    "filepath = f\"{TrainingHistoryPath}\\\\{name}.json\"\n",
    "with open(filepath, 'w') as f:\n",
    "    json.dump(history2.history, f)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "EnvPy3_12",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
